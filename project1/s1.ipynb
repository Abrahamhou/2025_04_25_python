{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8302fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函式庫導入完成。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 步驟 0：導入必要的函式庫\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "print(\"函式庫導入完成。\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7cec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功使用 'utf-8-sig' 編碼讀取檔案: 2023資料剖析後內容1~8月芝山到天母0609整理二版.csv\n",
      "\n",
      "原始資料共有 5016 筆。\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 步驟 1：資料載入與視覺化設定\n",
    "# =============================================================================\n",
    "# --- 設定 Matplotlib 顯示中文字體 ---\n",
    "try:\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # Windows\n",
    "except:\n",
    "    try:\n",
    "        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS'] # Mac\n",
    "    except:\n",
    "        print(\"警告：未找到指定的中文字體，圖表標題可能顯示為亂碼。\")\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# --- 載入資料 ---\n",
    "file_path = u'2023資料剖析後內容1~8月芝山到天母0609整理二版.csv' \n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "    print(f\"成功使用 'utf-8-sig' 編碼讀取檔案: {file_path}\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(file_path, encoding='big5')\n",
    "    print(f\"成功使用 'big5' 編碼讀取檔案: {file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"錯誤：找不到檔案 '{file_path}'。請確認檔案名稱和路徑是否正確。\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\n原始資料共有 {len(df)} 筆。\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a09a762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 開始進行資料處理與特徵工程 ---\n",
      "移除了 5016 筆無效或時間極端的資料。\n",
      "資料清理完成，剩餘有效資料 0 筆。\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m df_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStartExit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_clean[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStp1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(normalize_exit)\n\u001b[0;32m     61\u001b[0m ohe \u001b[38;5;241m=\u001b[39m OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, sparse_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m---> 62\u001b[0m encoded_features \u001b[38;5;241m=\u001b[39m \u001b[43mohe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStartExit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m new_feature_names \u001b[38;5;241m=\u001b[39m ohe\u001b[38;5;241m.\u001b[39mget_feature_names_out([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStartExit\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     64\u001b[0m encoded_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(encoded_features, columns\u001b[38;5;241m=\u001b[39mnew_feature_names, index\u001b[38;5;241m=\u001b[39mdf_clean\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\abrah\\miniconda3\\envs\\flask\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\abrah\\miniconda3\\envs\\flask\\lib\\site-packages\\sklearn\\base.py:892\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    877\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    878\u001b[0m             (\n\u001b[0;32m    879\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    888\u001b[0m         )\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\abrah\\miniconda3\\envs\\flask\\lib\\site-packages\\sklearn\\base.py:1363\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1359\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1360\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1361\u001b[0m     )\n\u001b[0;32m   1362\u001b[0m ):\n\u001b[1;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\abrah\\miniconda3\\envs\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:991\u001b[0m, in \u001b[0;36mOneHotEncoder.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    974\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m    Fit OneHotEncoder to X.\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;124;03m        Fitted encoder.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 991\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_drop_idx()\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_n_features_outs()\n",
      "File \u001b[1;32mc:\\Users\\abrah\\miniconda3\\envs\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:83\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[1;34m(self, X, handle_unknown, ensure_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[0;32m     81\u001b[0m _check_n_features(\u001b[38;5;28mself\u001b[39m, X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m _check_feature_names(\u001b[38;5;28mself\u001b[39m, X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 83\u001b[0m X_list, n_samples, n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m n_features\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\abrah\\miniconda3\\envs\\flask\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:65\u001b[0m, in \u001b[0;36m_BaseEncoder._check_X\u001b[1;34m(self, X, ensure_all_finite)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_features):\n\u001b[0;32m     64\u001b[0m     Xi \u001b[38;5;241m=\u001b[39m _safe_indexing(X, indices\u001b[38;5;241m=\u001b[39mi, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m     Xi \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneeds_validation\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     X_columns\u001b[38;5;241m.\u001b[39mappend(Xi)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_columns, n_samples, n_features\n",
      "File \u001b[1;32mc:\\Users\\abrah\\miniconda3\\envs\\flask\\lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1128\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1129\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1130\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1131\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1132\u001b[0m         )\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1135\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 步驟 2 & 3：資料清理、預處理與特徵工程 (合併與重構)\n",
    "# =============================================================================\n",
    "print(\"\\n--- 開始進行資料處理與特徵工程 ---\")\n",
    "\n",
    "# 使用 .copy() 創建一個明確的副本，避免 SettingWithCopyWarning\n",
    "df_processed = df.copy()\n",
    "\n",
    "# 移除檔案結尾可能存在的文字說明行 (判斷依據：Date 欄位為空)\n",
    "df_processed.dropna(subset=['Date'], inplace=True)\n",
    "\n",
    "# --- 欄位轉換與新增 ---\n",
    "# 2.1 轉換騎乘時間為秒數\n",
    "def parse_time_to_seconds(time_str):\n",
    "    try:\n",
    "        return pd.to_timedelta(time_str).total_seconds()\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan # 返回 NumPy 的 NaN，便於後續處理\n",
    "\n",
    "df_processed['TotalSeconds'] = df_processed['Time2'].apply(parse_time_to_seconds)\n",
    "\n",
    "# 2.2 轉換日期時間格式\n",
    "# 先確保 Date 欄位是乾淨的字串，再進行合併\n",
    "df_processed['Date_str'] = df_processed['Date'].astype(int).astype(str)\n",
    "df_processed['Datetime'] = pd.to_datetime(df_processed['Date_str'] + ' ' + df_processed['Time1'], format='%Y%m%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# --- 進行一次性的資料篩選 ---\n",
    "# 條件1: TotalSeconds 必須是有效的數值 (非 NaN)\n",
    "# 條件2: Datetime 必須是有效的日期 (非 NaT)\n",
    "# 條件3: 騎乘時間必須在合理範圍內 (3 到 60 分鐘)\n",
    "original_rows = len(df_processed)\n",
    "\n",
    "df_clean = df_processed[\n",
    "    (df_processed['TotalSeconds'].notna()) &\n",
    "    (df_processed['Datetime'].notna()) &\n",
    "    (df_processed['TotalSeconds'] >= 180) & \n",
    "    (df_processed['TotalSeconds'] <= 3600)\n",
    "].copy() # 再次使用 .copy() 確保是一個新的 DataFrame\n",
    "\n",
    "print(f\"移除了 {original_rows - len(df_clean)} 筆無效或時間極端的資料。\")\n",
    "print(f\"資料清理完成，剩餘有效資料 {len(df_clean)} 筆。\")\n",
    "\n",
    "\n",
    "# --- 特徵工程 (在乾淨的資料上進行) ---\n",
    "df_clean['TotalSeconds'] = df_clean['TotalSeconds'].astype(int)\n",
    "\n",
    "# 3.1 從 'Datetime' 提取時間特徵\n",
    "df_clean['Hour'] = df_clean['Datetime'].dt.hour\n",
    "df_clean['DayOfWeek'] = df_clean['Datetime'].dt.dayofweek\n",
    "df_clean['Month'] = df_clean['Datetime'].dt.month\n",
    "df_clean['IsWeekend'] = df_clean['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# 3.2 建立尖峰時段特徵\n",
    "df_clean['IsRushHour'] = df_clean['Hour'].apply(lambda h: 1 if (7 <= h <= 9) or (17 <= h <= 19) else 0)\n",
    "\n",
    "# 3.3 標準化起點站並進行 One-Hot Encoding\n",
    "def normalize_exit(stp_name):\n",
    "    return 'Exit_1' if '1號' in str(stp_name) else 'Exit_2'\n",
    "df_clean['StartExit'] = df_clean['Stp1'].apply(normalize_exit)\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False, dtype=np.int64)\n",
    "encoded_features = ohe.fit_transform(df_clean[['StartExit']])\n",
    "new_feature_names = ohe.get_feature_names_out(['StartExit'])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=new_feature_names, index=df_clean.index)\n",
    "df_final = pd.concat([df_clean, encoded_df], axis=1)\n",
    "\n",
    "# --- 準備最終用於建模的 DataFrame ---\n",
    "# 選擇我們需要的特徵欄位和目標欄位\n",
    "final_columns = ['TotalSeconds', 'Hour', 'DayOfWeek', 'Month', 'IsWeekend', 'IsRushHour'] + list(new_feature_names)\n",
    "df_model = df_final[final_columns].reset_index(drop=True) # 重設索引\n",
    "\n",
    "print(\"\\n特徵工程完成。\")\n",
    "print(\"最終用於建模的 DataFrame 預覽：\")\n",
    "print(df_model.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
